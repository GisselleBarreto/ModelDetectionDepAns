{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["!pip install scikit-learn\n","import numpy as np\n","import pandas as pd\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import GradientBoostingClassifier\n","from sklearn.metrics import accuracy_score\n"],"metadata":{"id":"hVJJAFAH_OBQ","executionInfo":{"status":"ok","timestamp":1758236501346,"user_tz":180,"elapsed":24154,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"colab":{"base_uri":"https://localhost:8080/"},"outputId":"a5d69ffd-61f7-4b0a-e4bb-13f3e0746e1c"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Requirement already satisfied: scikit-learn in /usr/local/lib/python3.12/dist-packages (1.6.1)\n","Requirement already satisfied: numpy>=1.19.5 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (2.0.2)\n","Requirement already satisfied: scipy>=1.6.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.16.1)\n","Requirement already satisfied: joblib>=1.2.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (1.5.2)\n","Requirement already satisfied: threadpoolctl>=3.1.0 in /usr/local/lib/python3.12/dist-packages (from scikit-learn) (3.6.0)\n"]}]},{"cell_type":"code","source":["# === Montar google drive ===\n","from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"sPy_Hl7p_Qxv","executionInfo":{"status":"ok","timestamp":1758236548018,"user_tz":180,"elapsed":23331,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"cb76f40a-522f-4941-a324-35a5daeb274f"},"execution_count":2,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["# Cargar datos de entrenamiento y prueba\n","df_train = pd.read_excel(\"/content/drive/MyDrive/MachineLearning/TRAIN/GPT/grouped_trainytrial.xlsx\")\n","df_test = pd.read_excel(\"/content/drive/MyDrive/MachineLearning/TEST/grouped_data_test.xlsx\")\n","\n","\n"],"metadata":{"id":"W84FNQQ8EDJv","executionInfo":{"status":"ok","timestamp":1758236574530,"user_tz":180,"elapsed":2544,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**Entrenar el modelo**"],"metadata":{"id":"yvqXjUUr_-jv"}},{"cell_type":"code","source":["import pandas as pd\n","from sklearn.ensemble import GradientBoostingClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    balanced_accuracy_score, classification_report\n",")\n","import joblib\n","\n","# === PREPROCESAMIENTO ===\n","label_encoder = LabelEncoder()\n","scaler = MinMaxScaler()\n","\n","# === Selección de características ===\n","columnas_seleccionadas = [\n","    'toxicity',\n","\n","    'POS','NEU','NEG',\n","\n","    'alegria', 'tristeza' ,'miedo','disgusto','enojo', 'sorpresa',\n","\n","    'yo', 'me', 'mi', 'mí',\n","\n","    'num_palabras_largas',\n","    #'num_signos_puntuacion'\n","    #'num_palabras_mayusculas',\n","    #'num_palabras_primera_mayuscula',\n","    'negaciones',\n","\n","    #'hora'\n","\n","    #'Medicamento_ansiedad','Medicamento_depresion',\n","\n","    'falta de motivacion',\n","    'aislamiento social',\n","    'pensamientos suicidas',\n","    #'baja autoestima',\n","\n","    #'insomnio',\n","    'pensamientos acelerados',\n","    #'ataques de panico',\n","]\n","\n","# === Extraer X e y ===\n","X_train = df_train[columnas_seleccionadas].copy()\n","y_train = label_encoder.fit_transform(df_train['label'])\n","\n","# === Escalado (solo de las columnas seleccionadas) ===\n","X_train[['num_palabras_largas', 'negaciones']] = scaler.fit_transform(\n","    X_train[['num_palabras_largas', 'negaciones']]\n",")\n","\n","\n","# === SPLIT VALIDACIÓN ===\n","X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n","    X_train, y_train, test_size=0.3, random_state=42\n",")\n","\n","# === HIPERPARÁMETROS MANUALES PARA GBM ===\n","modelo_gbm = GradientBoostingClassifier(\n","    loss='log_loss',\n","    learning_rate=0.1,\n","    n_estimators=100,\n","    max_depth=3,\n","    subsample=1.0,\n","    max_features=None,\n","    min_samples_split=2,\n","    random_state=42\n",")\n","\n","# === ENTRENAMIENTO ===\n","modelo_gbm.fit(X_train_split, y_train_split)\n","\n","# === PREDICCIÓN Y EVALUACIÓN ===\n","y_val_pred = modelo_gbm.predict(X_val_split)\n","\n","accuracy = accuracy_score(y_val_split, y_val_pred)\n","precision = precision_score(y_val_split, y_val_pred, average='weighted')\n","recall = recall_score(y_val_split, y_val_pred, average='weighted')\n","f1 = f1_score(y_val_split, y_val_pred, average='weighted')\n","balanced_accuracy = balanced_accuracy_score(y_val_split, y_val_pred)\n","\n","# === RESULTADOS ===\n","print(\"\\nResultados del modelo GBM:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_val_split, y_val_pred))\n","\n","# === GUARDAR MODELO Y TRANSFORMADORES ===\n","joblib.dump(modelo_gbm, 'gbm_model_manual.pkl')\n","joblib.dump(scaler, 'scaler.pkl')\n","joblib.dump(label_encoder, 'label_encoder.pkl')\n","joblib.dump(columnas_seleccionadas, 'columnas_seleccionadas.pkl')\n","joblib.dump(label_encoder.classes_, 'clases_modelo.pkl')\n","\n","print(\"\\nModelo GBM guardado exitosamente.\")"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"VXDuwxb2ADKG","executionInfo":{"status":"ok","timestamp":1758236811050,"user_tz":180,"elapsed":1485,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"6ebc2641-3d79-4002-e2cd-8a1fa5094789"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultados del modelo GBM:\n","Accuracy: 0.8219\n","Precision: 0.8219\n","Recall: 0.8219\n","F1 Score: 0.8219\n","Balanced Accuracy: 0.8097\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       0.86      0.86      0.86        76\n","           1       0.78      0.78      0.78        51\n","           2       0.79      0.79      0.79        19\n","\n","    accuracy                           0.82       146\n","   macro avg       0.81      0.81      0.81       146\n","weighted avg       0.82      0.82      0.82       146\n","\n","\n","Modelo GBM guardado exitosamente.\n"]}]},{"cell_type":"markdown","source":["**Pruebas con TEST**"],"metadata":{"id":"N--LeUrGCvMg"}},{"cell_type":"code","source":["import pandas as pd\n","import joblib\n","from sklearn.metrics import accuracy_score, precision_score, recall_score, f1_score, classification_report\n","\n","# === 1. Cargar modelo y transformadores ===\n","modelo_gbm = joblib.load('gbm_model_manual.pkl')  # Cargar el modelo GBM\n","scaler = joblib.load('scaler.pkl')\n","columnas_seleccionadas = joblib.load('columnas_seleccionadas.pkl')\n","label_encoder = joblib.load('label_encoder.pkl')  # Opcional, pero recomendado\n","\n","# === 2. Preprocesar conjunto de prueba ===\n","X_test = df_test.reindex(columns=columnas_seleccionadas, fill_value=0)\n","\n","# === Escalar solo columnas que fueron normalizadas ===\n","columnas_a_escalar = ['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']\n","columnas_presentes = [col for col in columnas_a_escalar if col in X_test.columns]\n","X_test.loc[:, columnas_presentes] = scaler.transform(X_test[columnas_presentes])\n","\n","# === Codificar etiquetas reales si fue usado LabelEncoder ===\n","y_test = label_encoder.transform(df_test['label']) if hasattr(label_encoder, 'classes_') else df_test['label']\n","\n","# === 3. Predicción ===\n","y_pred = modelo_gbm.predict(X_test)\n","\n","# === 4. Métricas ===\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","\n","print(\"Resultados finales en el conjunto de prueba (GBM):\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","\n","print(\"\\nReporte de Clasificación:\")\n","\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"GNWS-APYC0gZ","executionInfo":{"status":"ok","timestamp":1758236818822,"user_tz":180,"elapsed":234,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"7111d655-7970-4dd1-9633-4434bbfadc2a"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stdout","text":["Resultados finales en el conjunto de prueba (GBM):\n","Accuracy: 0.8200\n","Precision: 0.8251\n","Recall: 0.8200\n","F1 Score: 0.8168\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       0.87      0.94      0.90       200\n","           1       0.69      0.76      0.72       100\n","           2       0.88      0.64      0.74       100\n","\n","    accuracy                           0.82       400\n","   macro avg       0.81      0.78      0.79       400\n","weighted avg       0.83      0.82      0.82       400\n","\n"]},{"output_type":"stream","name":"stderr","text":["/tmp/ipython-input-536545660.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.11231884 0.02173913 0.01811594 0.08152174 0.04528986 0.27173913\n"," 0.07246377 0.01811594 0.04347826 0.04891304 0.3442029  0.09782609\n"," 0.01811594 0.13224638 0.11956522 0.0615942  0.05434783 0.09057971\n"," 0.04347826 0.21014493 0.0307971  0.14673913 0.05253623 0.08152174\n"," 0.10507246 0.125      0.23550725 0.04166667 0.04166667 0.1557971\n"," 0.25905797 0.07608696 0.03442029 0.25181159 0.06702899 0.05978261\n"," 0.20833333 0.05978261 0.05434783 0.04347826 0.20108696 0.08333333\n"," 0.04347826 0.04891304 0.15036232 0.20652174 0.04710145 0.01630435\n"," 0.1576087  0.15036232 0.10688406 0.01449275 0.0307971  0.08695652\n"," 0.10326087 0.02898551 0.33514493 0.05797101 0.08514493 0.06702899\n"," 0.04710145 0.22101449 0.10144928 0.11050725 0.03804348 0.02717391\n"," 0.04891304 0.01449275 0.02536232 0.03804348 0.15398551 0.11231884\n"," 0.02355072 0.08152174 0.0634058  0.04891304 0.10507246 0.09057971\n"," 0.19746377 0.13224638 0.02173913 0.02536232 0.16123188 0.08695652\n"," 0.08333333 0.00905797 0.01449275 0.07246377 0.03623188 0.04347826\n"," 0.06702899 0.32427536 0.13043478 0.01449275 0.01268116 0.01992754\n"," 0.05253623 0.03985507 0.09782609 0.02898551 0.25362319 0.13043478\n"," 0.03442029 0.04710145 0.04891304 0.07065217 0.02717391 0.05434783\n"," 0.07065217 0.23007246 0.02536232 0.05978261 0.19565217 0.05797101\n"," 0.02173913 0.07971014 0.04710145 0.01449275 0.02898551 0.0307971\n"," 0.03623188 0.05615942 0.08876812 0.00724638 0.59601449 0.02173913\n"," 0.01449275 0.0307971  0.01630435 0.12681159 0.125      0.04347826\n"," 0.05072464 0.05253623 0.05434783 0.01268116 0.04347826 0.26268116\n"," 0.10688406 0.0634058  0.27898551 0.05978261 0.05615942 0.07246377\n"," 0.01086957 0.22101449 0.22463768 0.03442029 0.28442029 0.09782609\n"," 0.14130435 0.01811594 0.07789855 0.02898551 0.13224638 0.33152174\n"," 0.07065217 0.08333333 0.05434783 0.01268116 0.02898551 0.01268116\n"," 0.05253623 0.07246377 0.04347826 0.32427536 0.11594203 0.04166667\n"," 0.0326087  0.57246377 0.01268116 0.15036232 0.06702899 0.1865942\n"," 0.06884058 0.00362319 0.04347826 0.07971014 0.08695652 0.04891304\n"," 0.13768116 0.20289855 0.19927536 0.15217391 0.10144928 0.00181159\n"," 0.0326087  0.01992754 0.14311594 0.18478261 0.02536232 0.24275362\n"," 0.0326087  0.03442029 0.04166667 0.00905797 0.71014493 0.03623188\n"," 0.01086957 0.05978261 0.03442029 0.15398551 0.08333333 0.03623188\n"," 0.05434783 0.10869565 0.20108696 0.05072464 0.07608696 0.10326087\n"," 0.04528986 0.15398551 0.03623188 0.01449275 0.05797101 0.1865942\n"," 0.01811594 0.01630435 0.01268116 0.44746377 0.14130435 0.08876812\n"," 0.06884058 0.09057971 0.0307971  0.05797101 0.08514493 0.2173913\n"," 0.03623188 0.01992754 0.01630435 0.00543478 0.03804348 0.03985507\n"," 0.10688406 0.05072464 0.02717391 0.01811594 0.09601449 0.02898551\n"," 0.03442029 0.02173913 0.07427536 0.01630435 0.00543478 0.16123188\n"," 0.02173913 0.05434783 0.10326087 0.05072464 0.10688406 0.22826087\n"," 0.01449275 0.0307971  0.16123188 0.00724638 0.04891304 0.04710145\n"," 0.08152174 0.01630435 0.13043478 0.02173913 0.07065217 0.00543478\n"," 0.0326087  0.19021739 0.02717391 0.01268116 0.07608696 0.03985507\n"," 0.04710145 0.06521739 0.12318841 0.05434783 0.0326087  0.05434783\n"," 0.01811594 0.01268116 0.04528986 0.0634058  0.14311594 0.15036232\n"," 0.5326087  0.05797101 0.00905797 0.07427536 0.35869565 0.02536232\n"," 0.05434783 0.04891304 0.03442029 0.06521739 0.0326087  0.09601449\n"," 0.04347826 0.13768116 0.11050725 0.10688406 0.04528986 0.01992754\n"," 0.04710145 0.16666667 0.13224638 0.03985507 0.0326087  0.04166667\n"," 0.12318841 0.03623188 0.01811594 0.05072464 0.23369565 0.05253623\n"," 0.04166667 0.32065217 0.07608696 0.01811594 0.15217391 0.04528986\n"," 0.0634058  0.06521739 0.02717391 0.02173913 0.03442029 0.00724638\n"," 0.11050725 0.0615942  0.05253623 0.0634058  0.01268116 0.08876812\n"," 0.0923913  0.00543478 0.01630435 0.05615942 0.01086957 0.06521739\n"," 0.04347826 0.03623188 0.11413043 0.08695652 0.0307971  0.0634058\n"," 0.05253623 0.00724638 0.13405797 0.0923913  0.04528986 0.04347826\n"," 0.04528986 0.18478261 0.02536232 0.01449275 0.02898551 0.01992754\n"," 0.03442029 0.0307971  0.08695652 0.01086957 0.01449275 0.18297101\n"," 0.14130435 0.03985507 0.10869565 0.04710145 0.01992754 0.05434783\n"," 0.00543478 0.04891304 0.14673913 0.06521739 0.01630435 0.08514493\n"," 0.01992754 0.0942029  0.01811594 0.12862319 0.03985507 0.10507246\n"," 0.04528986 0.01811594 0.00905797 0.07971014 0.02898551 0.02536232\n"," 0.14673913 0.01268116 0.13043478 0.04347826 0.09782609 0.01811594\n"," 0.22644928 0.02355072 0.04710145 0.06884058 0.05434783 0.01086957\n"," 0.02173913 0.10326087 0.00724638 0.06884058]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  X_test.loc[:, columnas_presentes] = scaler.transform(X_test[columnas_presentes])\n","/tmp/ipython-input-536545660.py:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.05 0.04 0.08 0.06 0.04 0.42 0.02 0.08 0.06 0.08 0.43 0.11 0.01 0.08\n"," 0.16 0.14 0.06 0.15 0.   0.17 0.05 0.5  0.01 0.15 0.13 0.21 0.38 0.04\n"," 0.06 0.64 0.45 0.1  0.03 0.36 0.14 0.07 0.17 0.31 0.1  0.08 0.25 0.16\n"," 0.07 0.02 0.24 0.57 0.01 0.12 0.19 0.27 0.13 0.02 0.04 0.09 0.12 0.05\n"," 0.44 0.11 0.06 0.14 0.16 0.37 0.23 0.16 0.05 0.08 0.1  0.04 0.11 0.07\n"," 0.25 0.11 0.07 0.11 0.13 0.09 0.18 0.13 0.4  0.11 0.01 0.04 0.27 0.28\n"," 0.1  0.01 0.   0.12 0.21 0.07 0.05 0.61 0.27 0.06 0.   0.06 0.06 0.09\n"," 0.12 0.   0.51 0.18 0.04 0.06 0.03 0.05 0.1  0.13 0.16 0.54 0.04 0.05\n"," 0.31 0.08 0.07 0.24 0.06 0.08 0.04 0.11 0.   0.08 0.02 0.03 1.15 0.\n"," 0.1  0.07 0.08 0.29 0.15 0.1  0.1  0.17 0.06 0.08 0.08 0.21 0.34 0.3\n"," 0.36 0.06 0.09 0.1  0.06 0.33 0.36 0.17 0.19 0.16 0.23 0.03 0.11 0.06\n"," 0.29 0.35 0.22 0.18 0.1  0.11 0.04 0.03 0.14 0.25 0.05 0.74 0.24 0.02\n"," 0.04 0.43 0.01 0.48 0.12 0.18 0.31 0.   0.14 0.1  0.11 0.11 0.27 0.32\n"," 0.33 0.34 0.13 0.01 0.07 0.02 0.13 0.45 0.03 0.4  0.05 0.08 0.08 0.02\n"," 0.02 0.06 0.   0.06 0.06 0.21 0.1  0.06 0.2  0.19 0.2  0.05 0.23 0.03\n"," 0.16 0.28 0.14 0.06 0.08 0.02 0.01 0.02 0.06 0.52 0.18 0.08 0.18 0.07\n"," 0.02 0.15 0.14 0.22 0.09 0.05 0.03 0.01 0.03 0.03 0.09 0.07 0.13 0.11\n"," 0.08 0.02 0.02 0.02 0.13 0.07 0.01 0.21 0.01 0.09 0.17 0.05 0.08 0.27\n"," 0.04 0.07 0.21 0.02 0.13 0.05 0.18 0.01 0.19 0.1  0.05 0.03 0.09 0.4\n"," 0.12 0.04 0.29 0.03 0.06 0.09 0.2  0.13 0.03 0.14 0.09 0.   0.15 0.16\n"," 0.2  0.27 0.4  0.17 0.03 0.07 0.3  0.11 0.06 0.06 0.15 0.15 0.08 0.23\n"," 0.02 0.15 0.16 0.14 0.2  0.03 0.17 0.09 0.38 0.07 0.05 0.11 0.23 0.12\n"," 0.01 0.12 0.51 0.06 0.11 0.77 0.08 0.13 0.25 0.09 0.12 0.05 0.1  0.08\n"," 0.11 0.03 0.09 0.13 0.25 0.08 0.04 0.11 0.23 0.04 0.05 0.1  0.07 0.12\n"," 0.29 0.19 0.21 0.35 0.06 0.11 0.09 0.02 0.38 0.13 0.06 0.06 0.23 0.01\n"," 0.12 0.08 0.06 0.05 0.07 0.05 0.18 0.12 0.06 0.38 0.15 0.06 0.23 0.15\n"," 0.02 0.22 0.02 0.08 0.3  0.05 0.02 0.12 0.05 0.04 0.04 0.09 0.14 0.12\n"," 0.   0.03 0.06 0.18 0.02 0.   0.16 0.05 0.03 0.09 0.22 0.01 0.22 0.01\n"," 0.17 0.07 0.15 0.04 0.01 0.12 0.06 0.09]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  X_test.loc[:, columnas_presentes] = scaler.transform(X_test[columnas_presentes])\n"]}]}]}