{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[],"authorship_tag":"ABX9TyM287ZieYCurTD+pW+1AF2Q"},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"8Xn5rhAPmSj9","executionInfo":{"status":"ok","timestamp":1747518717502,"user_tz":180,"elapsed":41491,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"8203763b-8698-47f2-fe04-498a2a052c5c"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## Montar google drive\n","from google.colab import drive\n","drive.mount('/content/drive')\n"]},{"cell_type":"code","source":["# Cargar el archivo desde Google Drive\n","import pandas as pd\n","# Cargar datos de entrenamiento y prueba\n","df_train = pd.read_excel(\"/content/drive/MyDrive/MachineLearning/TRAIN/GPT/grouped_trainytrial.xlsx\")\n","df_test = pd.read_excel(\"/content/drive/MyDrive/MachineLearning/TEST/grouped_data_test.xlsx\")\n","\n"],"metadata":{"id":"jfZOWQD9nCCJ","executionInfo":{"status":"ok","timestamp":1747518724378,"user_tz":180,"elapsed":4283,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["import pandas as pd\n","from lightgbm import LGBMClassifier\n","from imblearn.over_sampling import SMOTE\n","from sklearn.model_selection import train_test_split\n","from sklearn.preprocessing import LabelEncoder, MinMaxScaler\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score,\n","    balanced_accuracy_score, classification_report\n",")\n","import joblib\n","\n","# === PREPROCESAMIENTO ===\n","label_encoder = LabelEncoder()\n","scaler = MinMaxScaler()\n","\n","# Selección de características\n","columnas_seleccionadas = [\n","    'POS', 'NEU', 'NEG', 'tristeza', 'miedo', 'disgusto', 'enojo', 'sorpresa', 'alegria',\n","     'toxicity',\n","    'me', 'mi', 'yo',\n","    'num_palabras_mayusculas',\n","    'num_palabras_largas',\n","    'negaciones',\n","    'falta de motivacion',\n","   'aislamiento social',\n","    'pensamientos suicidas',\n","\n","]\n","\n","X_train = df_train[columnas_seleccionadas].copy()\n","X_train[['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']] = scaler.fit_transform(\n","    X_train[['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']]\n",")\n","\n","y_train = label_encoder.fit_transform(df_train['label'])\n","\n","\n","# === SPLIT VALIDACIÓN ===\n","X_train_split, X_val_split, y_train_split, y_val_split = train_test_split(\n","    X_train, y_train, test_size=0.3, random_state=42\n",")\n","\n","\n","modelo_manual = LGBMClassifier(\n","    objective='multiclass',\n","    num_class=3,\n","    boosting_type='gbdt',\n","    n_estimators=100,\n","    num_leaves=31,\n","    learning_rate=0.05,\n","    feature_fraction=0.7,\n","    verbosity=-1,\n","    random_state=42\n",")\n","# === ENTRENAMIENTO ===\n","modelo_manual.fit(X_train_split, y_train_split)\n","\n","# === PREDICCIÓN Y EVALUACIÓN ===\n","y_val_pred = modelo_manual.predict(X_val_split)\n","\n","accuracy = accuracy_score(y_val_split, y_val_pred)\n","precision = precision_score(y_val_split, y_val_pred, average='weighted')\n","recall = recall_score(y_val_split, y_val_pred, average='weighted')\n","f1 = f1_score(y_val_split, y_val_pred, average='weighted')\n","balanced_accuracy = balanced_accuracy_score(y_val_split, y_val_pred)\n","\n","# === RESULTADOS ===\n","print(\"\\nResultados del modelo con hiperparámetros manuales:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_val_split, y_val_pred,target_names=[\"control\", \"depresion\", \"ansiedad\"]))\n","\n","\n","\n","# === GUARDAR MODELO Y TRANSFORMADORES ===\n","joblib.dump(modelo_manual, 'lgbm_model.pkl')\n","joblib.dump(scaler, 'scaler.pkl')\n","joblib.dump(label_encoder, 'label_encoder.pkl')\n","joblib.dump(columnas_seleccionadas, 'columnas_seleccionadas.pkl')\n","joblib.dump(label_encoder.classes_, 'clases_modelo.pkl')\n","\n","print(\"\\nModelo con hiperparámetros definidos manualmente guardado exitosamente.\")\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"_OJrnqnpoaSQ","executionInfo":{"status":"ok","timestamp":1747519318772,"user_tz":180,"elapsed":147,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"42c3a29a-5f3b-47f5-dabd-e5204a684ecb"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultados del modelo con hiperparámetros manuales:\n","Accuracy: 0.8219\n","Precision: 0.8226\n","Recall: 0.8219\n","F1 Score: 0.8222\n","Balanced Accuracy: 0.8097\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","     control       0.87      0.86      0.86        76\n","   depresion       0.77      0.78      0.78        51\n","    ansiedad       0.79      0.79      0.79        19\n","\n","    accuracy                           0.82       146\n","   macro avg       0.81      0.81      0.81       146\n","weighted avg       0.82      0.82      0.82       146\n","\n","\n","Modelo con hiperparámetros definidos manualmente guardado exitosamente.\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import joblib\n","from sklearn.metrics import (\n","    accuracy_score, precision_score, recall_score, f1_score, balanced_accuracy_score, classification_report\n",")\n","\n","# Cargar el modelo y preprocesadores guardados\n","modelo_optimizado = joblib.load('lgbm_model.pkl')\n","scaler = joblib.load('scaler.pkl')\n","label_encoder = joblib.load('label_encoder.pkl')\n","columnas_seleccionadas = joblib.load('columnas_seleccionadas.pkl')\n","\n","# Preprocesamiento del conjunto de prueba\n","X_test = df_test[columnas_seleccionadas].copy()\n","\n","# Escalar las columnas numéricas\n","X_test.loc[:, ['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']] = scaler.transform(\n","    X_test[['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']]\n",")\n","\n","# Codificar las etiquetas del conjunto de prueba\n","y_test = label_encoder.transform(df_test['label'])\n","\n","# Hacer predicciones en el conjunto de prueba\n","y_pred = modelo_optimizado.predict(X_test)\n","\n","# Calcular métricas\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted')\n","recall = recall_score(y_test, y_pred, average='weighted')\n","f1 = f1_score(y_test, y_pred, average='weighted')\n","balanced_accuracy = balanced_accuracy_score(y_test, y_pred)\n","\n","# Imprimir métricas\n","print(\"\\nResultados en el conjunto de prueba:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","print(f\"Balanced Accuracy: {balanced_accuracy:.4f}\")\n","\n","# Reporte de clasificación detallado\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_test, y_pred))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"W-k2FlR12b8E","executionInfo":{"status":"ok","timestamp":1747519325618,"user_tz":180,"elapsed":129,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"325edc34-dc85-44aa-cd0e-f41b3cd978a2"},"execution_count":8,"outputs":[{"output_type":"stream","name":"stdout","text":["\n","Resultados en el conjunto de prueba:\n","Accuracy: 0.8175\n","Precision: 0.8200\n","Recall: 0.8175\n","F1 Score: 0.8148\n","Balanced Accuracy: 0.7767\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","           0       0.88      0.94      0.91       200\n","           1       0.68      0.74      0.71       100\n","           2       0.84      0.65      0.73       100\n","\n","    accuracy                           0.82       400\n","   macro avg       0.80      0.78      0.78       400\n","weighted avg       0.82      0.82      0.81       400\n","\n"]},{"output_type":"stream","name":"stderr","text":["<ipython-input-8-0e1d69c19bfa>:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.01128668 0.00225734 0.02257336 0.         0.00451467 0.04063205\n"," 0.00451467 0.         0.01580135 0.00677201 0.03611738 0.00902935\n"," 0.00677201 0.00902935 0.00677201 0.00902935 0.00451467 0.00677201\n"," 0.00225734 0.00451467 0.01580135 0.02708804 0.00902935 0.00225734\n"," 0.00902935 0.01354402 0.02934537 0.00677201 0.00902935 0.00225734\n"," 0.03837472 0.00225734 0.00451467 0.0248307  0.02031603 0.02031603\n"," 0.01128668 0.01805869 0.02031603 0.00451467 0.01354402 0.00225734\n"," 0.00677201 0.00225734 0.01128668 0.00451467 0.00225734 0.00451467\n"," 0.00451467 0.01128668 0.01128668 0.00451467 0.00225734 0.01128668\n"," 0.0248307  0.         0.04288939 0.01805869 0.01128668 0.01128668\n"," 0.02708804 0.01805869 0.01128668 0.0248307  0.00225734 0.\n"," 0.01128668 0.00225734 0.02708804 0.01128668 0.02708804 0.00677201\n"," 0.         0.         0.00451467 0.         0.03386005 0.00451467\n"," 0.03386005 0.00225734 0.03611738 0.00225734 0.00902935 0.00677201\n"," 0.00902935 0.00677201 0.00225734 0.00902935 0.01805869 0.00677201\n"," 0.00225734 0.02708804 0.01580135 0.00677201 0.00225734 0.00902935\n"," 0.00902935 0.00225734 0.00225734 0.00451467 0.04063205 0.01805869\n"," 0.01580135 0.00451467 0.00677201 0.01580135 0.02031603 0.00225734\n"," 0.         0.04514673 0.         0.01354402 0.00902935 0.00677201\n"," 0.00225734 0.         0.00225734 0.00677201 0.00225734 0.01805869\n"," 0.00902935 0.03160271 0.03386005 0.01128668 0.10158014 0.\n"," 0.         0.00225734 0.00902935 0.01354402 0.02257336 0.01354402\n"," 0.         0.00902935 0.01354402 0.01128668 0.00677201 0.\n"," 0.00225734 0.01580135 0.01580135 0.00902935 0.00677201 0.\n"," 0.         0.00225734 0.         0.00677201 0.01580135 0.01128668\n"," 0.00677201 0.         0.02708804 0.         0.         0.03160271\n"," 0.00451467 0.01128668 0.01128668 0.         0.00451467 0.00451467\n"," 0.00902935 0.         0.01128668 0.01805869 0.0496614  0.02031603\n"," 0.         0.02257336 0.         0.         0.02257336 0.01580135\n"," 0.01128668 0.         0.         0.06772009 0.01128668 0.00225734\n"," 0.         0.0248307  0.03611738 0.01805869 0.02257336 0.00225734\n"," 0.00677201 0.00225734 0.00451467 0.02934537 0.00677201 0.06094808\n"," 0.01354402 0.01128668 0.00451467 0.00225734 0.8510158  0.00902935\n"," 0.         0.00677201 0.00677201 0.00225734 0.01580135 0.00677201\n"," 0.01354402 0.02257336 0.00902935 0.00225734 0.00225734 0.00225734\n"," 0.00902935 0.01354402 0.00677201 0.         0.00451467 0.36343115\n"," 0.00225734 0.00225734 0.00677201 0.01805869 0.00677201 0.0248307\n"," 0.03386005 0.01354402 0.         0.04514673 0.01805869 0.01805869\n"," 0.00225734 0.00451467 0.00451467 0.00225734 0.00225734 0.02257336\n"," 0.00451467 0.01354402 0.00902935 0.00225734 0.01128668 0.\n"," 0.01128668 0.         0.         0.         0.         0.02257336\n"," 0.00225734 0.00451467 0.01128668 0.01128668 0.         0.03611738\n"," 0.00902935 0.00677201 0.02708804 0.         0.04514673 0.00225734\n"," 0.00451467 0.00451467 0.00902935 0.00225734 0.00677201 0.\n"," 0.00225734 0.00677201 0.00902935 0.01580135 0.00451467 0.02257336\n"," 0.00677201 0.01354402 0.         0.00225734 0.00451467 0.00451467\n"," 0.01354402 0.00451467 0.00225734 0.00902935 0.01580135 0.00225734\n"," 0.02257336 0.00677201 0.01128668 0.02031603 0.03386005 0.00902935\n"," 0.03160271 0.00451467 0.01580135 0.03386005 0.00677201 0.00225734\n"," 0.00225734 0.00225734 0.02708804 0.00451467 0.02934537 0.\n"," 0.         0.00451467 0.00677201 0.02708804 0.01580135 0.00451467\n"," 0.00902935 0.00225734 0.         0.01128668 0.03386005 0.01128668\n"," 0.02257336 0.01805869 0.01128668 0.00902935 0.00451467 0.03386005\n"," 0.00225734 0.00677201 0.00225734 0.         0.01128668 0.00451467\n"," 0.02934537 0.00677201 0.02257336 0.00902935 0.00677201 0.00451467\n"," 0.01128668 0.         0.00225734 0.00902935 0.         0.02031603\n"," 0.01805869 0.02031603 0.01128668 0.00677201 0.02934537 0.00225734\n"," 0.00451467 0.00451467 0.0744921  0.00677201 0.00225734 0.03611738\n"," 0.00225734 0.16704289 0.01354402 0.00451467 0.02934537 0.00451467\n"," 0.04740406 0.00225734 0.00902935 0.00902935 0.         0.0248307\n"," 0.10158014 0.00677201 0.03611738 0.         0.         0.00451467\n"," 0.00902935 0.00451467 0.05191874 0.00225734 0.         0.00902935\n"," 0.00451467 0.01354402 0.00451467 0.00225734 0.01580135 0.01805869\n"," 0.07674944 0.00677201 0.00225734 0.01354402 0.00225734 0.00451467\n"," 0.02257336 0.         0.01805869 0.00451467 0.00225734 0.00451467\n"," 0.00451467 0.00451467 0.         0.00225734 0.00451467 0.00677201\n"," 0.00677201 0.01580135 0.         0.04063205]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  X_test.loc[:, ['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']] = scaler.transform(\n","<ipython-input-8-0e1d69c19bfa>:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.11231884 0.02173913 0.01811594 0.08152174 0.04528986 0.27173913\n"," 0.07246377 0.01811594 0.04347826 0.04891304 0.3442029  0.09782609\n"," 0.01811594 0.13224638 0.11956522 0.0615942  0.05434783 0.09057971\n"," 0.04347826 0.21014493 0.0307971  0.14673913 0.05253623 0.08152174\n"," 0.10507246 0.125      0.23550725 0.04166667 0.04166667 0.1557971\n"," 0.25905797 0.07608696 0.03442029 0.25181159 0.06702899 0.05978261\n"," 0.20833333 0.05978261 0.05434783 0.04347826 0.20108696 0.08333333\n"," 0.04347826 0.04891304 0.15036232 0.20652174 0.04710145 0.01630435\n"," 0.1576087  0.15036232 0.10688406 0.01449275 0.0307971  0.08695652\n"," 0.10326087 0.02898551 0.33514493 0.05797101 0.08514493 0.06702899\n"," 0.04710145 0.22101449 0.10144928 0.11050725 0.03804348 0.02717391\n"," 0.04891304 0.01449275 0.02536232 0.03804348 0.15398551 0.11231884\n"," 0.02355072 0.08152174 0.0634058  0.04891304 0.10507246 0.09057971\n"," 0.19746377 0.13224638 0.02173913 0.02536232 0.16123188 0.08695652\n"," 0.08333333 0.00905797 0.01449275 0.07246377 0.03623188 0.04347826\n"," 0.06702899 0.32427536 0.13043478 0.01449275 0.01268116 0.01992754\n"," 0.05253623 0.03985507 0.09782609 0.02898551 0.25362319 0.13043478\n"," 0.03442029 0.04710145 0.04891304 0.07065217 0.02717391 0.05434783\n"," 0.07065217 0.23007246 0.02536232 0.05978261 0.19565217 0.05797101\n"," 0.02173913 0.07971014 0.04710145 0.01449275 0.02898551 0.0307971\n"," 0.03623188 0.05615942 0.08876812 0.00724638 0.59601449 0.02173913\n"," 0.01449275 0.0307971  0.01630435 0.12681159 0.125      0.04347826\n"," 0.05072464 0.05253623 0.05434783 0.01268116 0.04347826 0.26268116\n"," 0.10688406 0.0634058  0.27898551 0.05978261 0.05615942 0.07246377\n"," 0.01086957 0.22101449 0.22463768 0.03442029 0.28442029 0.09782609\n"," 0.14130435 0.01811594 0.07789855 0.02898551 0.13224638 0.33152174\n"," 0.07065217 0.08333333 0.05434783 0.01268116 0.02898551 0.01268116\n"," 0.05253623 0.07246377 0.04347826 0.32427536 0.11594203 0.04166667\n"," 0.0326087  0.57246377 0.01268116 0.15036232 0.06702899 0.1865942\n"," 0.06884058 0.00362319 0.04347826 0.07971014 0.08695652 0.04891304\n"," 0.13768116 0.20289855 0.19927536 0.15217391 0.10144928 0.00181159\n"," 0.0326087  0.01992754 0.14311594 0.18478261 0.02536232 0.24275362\n"," 0.0326087  0.03442029 0.04166667 0.00905797 0.71014493 0.03623188\n"," 0.01086957 0.05978261 0.03442029 0.15398551 0.08333333 0.03623188\n"," 0.05434783 0.10869565 0.20108696 0.05072464 0.07608696 0.10326087\n"," 0.04528986 0.15398551 0.03623188 0.01449275 0.05797101 0.1865942\n"," 0.01811594 0.01630435 0.01268116 0.44746377 0.14130435 0.08876812\n"," 0.06884058 0.09057971 0.0307971  0.05797101 0.08514493 0.2173913\n"," 0.03623188 0.01992754 0.01630435 0.00543478 0.03804348 0.03985507\n"," 0.10688406 0.05072464 0.02717391 0.01811594 0.09601449 0.02898551\n"," 0.03442029 0.02173913 0.07427536 0.01630435 0.00543478 0.16123188\n"," 0.02173913 0.05434783 0.10326087 0.05072464 0.10688406 0.22826087\n"," 0.01449275 0.0307971  0.16123188 0.00724638 0.04891304 0.04710145\n"," 0.08152174 0.01630435 0.13043478 0.02173913 0.07065217 0.00543478\n"," 0.0326087  0.19021739 0.02717391 0.01268116 0.07608696 0.03985507\n"," 0.04710145 0.06521739 0.12318841 0.05434783 0.0326087  0.05434783\n"," 0.01811594 0.01268116 0.04528986 0.0634058  0.14311594 0.15036232\n"," 0.5326087  0.05797101 0.00905797 0.07427536 0.35869565 0.02536232\n"," 0.05434783 0.04891304 0.03442029 0.06521739 0.0326087  0.09601449\n"," 0.04347826 0.13768116 0.11050725 0.10688406 0.04528986 0.01992754\n"," 0.04710145 0.16666667 0.13224638 0.03985507 0.0326087  0.04166667\n"," 0.12318841 0.03623188 0.01811594 0.05072464 0.23369565 0.05253623\n"," 0.04166667 0.32065217 0.07608696 0.01811594 0.15217391 0.04528986\n"," 0.0634058  0.06521739 0.02717391 0.02173913 0.03442029 0.00724638\n"," 0.11050725 0.0615942  0.05253623 0.0634058  0.01268116 0.08876812\n"," 0.0923913  0.00543478 0.01630435 0.05615942 0.01086957 0.06521739\n"," 0.04347826 0.03623188 0.11413043 0.08695652 0.0307971  0.0634058\n"," 0.05253623 0.00724638 0.13405797 0.0923913  0.04528986 0.04347826\n"," 0.04528986 0.18478261 0.02536232 0.01449275 0.02898551 0.01992754\n"," 0.03442029 0.0307971  0.08695652 0.01086957 0.01449275 0.18297101\n"," 0.14130435 0.03985507 0.10869565 0.04710145 0.01992754 0.05434783\n"," 0.00543478 0.04891304 0.14673913 0.06521739 0.01630435 0.08514493\n"," 0.01992754 0.0942029  0.01811594 0.12862319 0.03985507 0.10507246\n"," 0.04528986 0.01811594 0.00905797 0.07971014 0.02898551 0.02536232\n"," 0.14673913 0.01268116 0.13043478 0.04347826 0.09782609 0.01811594\n"," 0.22644928 0.02355072 0.04710145 0.06884058 0.05434783 0.01086957\n"," 0.02173913 0.10326087 0.00724638 0.06884058]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  X_test.loc[:, ['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']] = scaler.transform(\n","<ipython-input-8-0e1d69c19bfa>:17: FutureWarning: Setting an item of incompatible dtype is deprecated and will raise in a future error of pandas. Value '[0.05 0.04 0.08 0.06 0.04 0.42 0.02 0.08 0.06 0.08 0.43 0.11 0.01 0.08\n"," 0.16 0.14 0.06 0.15 0.   0.17 0.05 0.5  0.01 0.15 0.13 0.21 0.38 0.04\n"," 0.06 0.64 0.45 0.1  0.03 0.36 0.14 0.07 0.17 0.31 0.1  0.08 0.25 0.16\n"," 0.07 0.02 0.24 0.57 0.01 0.12 0.19 0.27 0.13 0.02 0.04 0.09 0.12 0.05\n"," 0.44 0.11 0.06 0.14 0.16 0.37 0.23 0.16 0.05 0.08 0.1  0.04 0.11 0.07\n"," 0.25 0.11 0.07 0.11 0.13 0.09 0.18 0.13 0.4  0.11 0.01 0.04 0.27 0.28\n"," 0.1  0.01 0.   0.12 0.21 0.07 0.05 0.61 0.27 0.06 0.   0.06 0.06 0.09\n"," 0.12 0.   0.51 0.18 0.04 0.06 0.03 0.05 0.1  0.13 0.16 0.54 0.04 0.05\n"," 0.31 0.08 0.07 0.24 0.06 0.08 0.04 0.11 0.   0.08 0.02 0.03 1.15 0.\n"," 0.1  0.07 0.08 0.29 0.15 0.1  0.1  0.17 0.06 0.08 0.08 0.21 0.34 0.3\n"," 0.36 0.06 0.09 0.1  0.06 0.33 0.36 0.17 0.19 0.16 0.23 0.03 0.11 0.06\n"," 0.29 0.35 0.22 0.18 0.1  0.11 0.04 0.03 0.14 0.25 0.05 0.74 0.24 0.02\n"," 0.04 0.43 0.01 0.48 0.12 0.18 0.31 0.   0.14 0.1  0.11 0.11 0.27 0.32\n"," 0.33 0.34 0.13 0.01 0.07 0.02 0.13 0.45 0.03 0.4  0.05 0.08 0.08 0.02\n"," 0.02 0.06 0.   0.06 0.06 0.21 0.1  0.06 0.2  0.19 0.2  0.05 0.23 0.03\n"," 0.16 0.28 0.14 0.06 0.08 0.02 0.01 0.02 0.06 0.52 0.18 0.08 0.18 0.07\n"," 0.02 0.15 0.14 0.22 0.09 0.05 0.03 0.01 0.03 0.03 0.09 0.07 0.13 0.11\n"," 0.08 0.02 0.02 0.02 0.13 0.07 0.01 0.21 0.01 0.09 0.17 0.05 0.08 0.27\n"," 0.04 0.07 0.21 0.02 0.13 0.05 0.18 0.01 0.19 0.1  0.05 0.03 0.09 0.4\n"," 0.12 0.04 0.29 0.03 0.06 0.09 0.2  0.13 0.03 0.14 0.09 0.   0.15 0.16\n"," 0.2  0.27 0.4  0.17 0.03 0.07 0.3  0.11 0.06 0.06 0.15 0.15 0.08 0.23\n"," 0.02 0.15 0.16 0.14 0.2  0.03 0.17 0.09 0.38 0.07 0.05 0.11 0.23 0.12\n"," 0.01 0.12 0.51 0.06 0.11 0.77 0.08 0.13 0.25 0.09 0.12 0.05 0.1  0.08\n"," 0.11 0.03 0.09 0.13 0.25 0.08 0.04 0.11 0.23 0.04 0.05 0.1  0.07 0.12\n"," 0.29 0.19 0.21 0.35 0.06 0.11 0.09 0.02 0.38 0.13 0.06 0.06 0.23 0.01\n"," 0.12 0.08 0.06 0.05 0.07 0.05 0.18 0.12 0.06 0.38 0.15 0.06 0.23 0.15\n"," 0.02 0.22 0.02 0.08 0.3  0.05 0.02 0.12 0.05 0.04 0.04 0.09 0.14 0.12\n"," 0.   0.03 0.06 0.18 0.02 0.   0.16 0.05 0.03 0.09 0.22 0.01 0.22 0.01\n"," 0.17 0.07 0.15 0.04 0.01 0.12 0.06 0.09]' has dtype incompatible with int64, please explicitly cast to a compatible dtype first.\n","  X_test.loc[:, ['num_palabras_mayusculas', 'num_palabras_largas', 'negaciones']] = scaler.transform(\n"]}]}]}