{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"prvFwN4iZlhs","executionInfo":{"status":"ok","timestamp":1749927586024,"user_tz":180,"elapsed":24654,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"27fc73ea-25be-45ec-dc4f-e7b903167312"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}],"source":["## Montar google drive\n","from google.colab import drive\n","drive.mount('/content/drive')"]},{"cell_type":"code","source":["# Cargar el archivo desde Google Drive\n","import pandas as pd\n","\n","\n","# Especifica la ruta completa del archivo en tu Google Drive\n","#file_path = '/content/drive/MyDrive/MachineLearning/Mensajes Concatenados.xlsx'\n","#file_path = '/content/drive/MyDrive/Tesis- Borradores/FASE 1/TEST/Mensajes Concatenados.xlsx'\n","file_path = '/content/drive/MyDrive/MachineLearning/TRAIN/GPT/Mensajes Concatenados_trainytrial.xlsx'\n","\n","# Cargar el archivo Excel en un DataFrame\n","df = pd.read_excel(file_path)"],"metadata":{"id":"dVtXAJyTZrGD","executionInfo":{"status":"ok","timestamp":1749927611754,"user_tz":180,"elapsed":72,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}}},"execution_count":4,"outputs":[]},{"cell_type":"markdown","source":["**Random Forest**"],"metadata":{"id":"kHMsQkjbMwHd"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import string\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.ensemble import RandomForestClassifier\n","from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import nltk\n","from lightgbm import LGBMClassifier\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Preprocesamiento de texto\n","def preprocess_text(text):\n","    # Convertir a minúsculas\n","    text = text.lower()\n","    # Eliminar puntuación\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    # Eliminar números\n","    text = ''.join([char for char in text if not char.isdigit()])\n","    # Tokenizar palabras\n","    words = text.split()\n","    # Eliminar stopwords\n","    stop_words = set(stopwords.words('spanish'))\n","    words = [word for word in words if word not in stop_words]\n","    # Lematización\n","    lemmatizer = WordNetLemmatizer()\n","    words = [lemmatizer.lemmatize(word) for word in words]\n","    return ' '.join(words)\n","\n","# Aplicar preprocesamiento\n","df['message_cleaned'] = df['message'].apply(preprocess_text)\n","\n","# Separar características y etiquetas\n","X = df['message_cleaned']\n","y = df['label']\n","\n","# Transformar en Bag of Words\n","vectorizer = CountVectorizer()\n","X_bow = vectorizer.fit_transform(X)\n","\n","# Dividir en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n","\n","\n","\n","###############################################################################################\n","# Modelo Random Forest\n","###############################################################################################\n","\n","rf_model = RandomForestClassifier(\n","    max_depth=12,\n","    max_features='sqrt',\n","    min_samples_leaf=1,\n","    min_samples_split=5,\n","    n_estimators=500,\n","    random_state=42,\n","    class_weight='balanced'\n",")\n","rf_model.fit(X_train, y_train)\n","\n","# Predicción\n","y_pred = rf_model.predict(X_test)\n","\n","# # Evaluación\n","# accuracy = accuracy_score(y_test, y_pred)\n","# print(f'\\nAccuracy: {accuracy * 100:.2f}%')\n","\n","# # Reporte de clasificación\n","# print(\"\\nReporte de clasificación:\")\n","# print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n","\n","\n","# Calcular métricas adicionales\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n","recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n","f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n","\n","# Imprimir resultados\n","print(\"\\nResultados de las métricas:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","\n","# Reporte de clasificación detallado\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"4mDiMhk2akcv","executionInfo":{"status":"ok","timestamp":1749927662274,"user_tz":180,"elapsed":15701,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"98a2cf90-71ff-489d-85c2-b997c79dda23","collapsed":true},"execution_count":6,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n"]},{"output_type":"stream","name":"stdout","text":["\n","Resultados de las métricas:\n","Accuracy: 0.6701\n","Precision: 0.7304\n","Recall: 0.6701\n","F1 Score: 0.6504\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","     Ninguno       0.59      0.91      0.72        45\n","   Depresión       0.82      0.38      0.52        37\n","    Ansiedad       0.91      0.67      0.77        15\n","\n","    accuracy                           0.67        97\n","   macro avg       0.78      0.65      0.67        97\n","weighted avg       0.73      0.67      0.65        97\n","\n"]}]},{"cell_type":"markdown","source":["**LGBM**"],"metadata":{"id":"uFPabuD6Mz93"}},{"cell_type":"code","source":["# Convertir la matriz de características a tipo flotante\n","X_train = X_train.astype(np.float32)\n","X_test = X_test.astype(np.float32)\n","\n","# Modelo LightGBM\n","lgbm_model = LGBMClassifier(\n","    objective='multiclass',\n","    num_class=3,\n","    boosting_type='gbdt',\n","    n_estimators=100,\n","    num_leaves=31,\n","    learning_rate=0.05,\n","    feature_fraction=0.7,\n","    verbosity=-1,\n","    random_state=42,\n","    class_weight='balanced'\n",")\n","\n","# Entrenamiento\n","lgbm_model.fit(X_train, y_train)\n","\n","# Predicción\n","y_pred = lgbm_model.predict(X_test)\n","\n","# Calcular métricas adicionales\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n","recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n","f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n","\n","# Imprimir resultados\n","print(\"\\nResultados de las métricas:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","\n","# Reporte de clasificación detallado\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"collapsed":true,"id":"4ChO6498M2Au","executionInfo":{"status":"ok","timestamp":1749927667641,"user_tz":180,"elapsed":359,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"9aaa17c2-d32f-44b8-df5b-6d2aeaaf08d7"},"execution_count":7,"outputs":[{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]},{"output_type":"stream","name":"stdout","text":["\n","Resultados de las métricas:\n","Accuracy: 0.6804\n","Precision: 0.6949\n","Recall: 0.6804\n","F1 Score: 0.6741\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","     Ninguno       0.67      0.76      0.71        45\n","   Depresión       0.76      0.51      0.61        37\n","    Ansiedad       0.62      0.87      0.72        15\n","\n","    accuracy                           0.68        97\n","   macro avg       0.68      0.71      0.68        97\n","weighted avg       0.69      0.68      0.67        97\n","\n"]},{"output_type":"stream","name":"stderr","text":["/usr/local/lib/python3.11/dist-packages/sklearn/utils/deprecation.py:151: FutureWarning: 'force_all_finite' was renamed to 'ensure_all_finite' in 1.6 and will be removed in 1.8.\n","  warnings.warn(\n"]}]},{"cell_type":"markdown","source":["** **texto en negrita**XG BOOST**"],"metadata":{"id":"v9OKHRqa1wRm"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import string\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import nltk\n","from xgboost import XGBClassifier\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Preprocesamiento de texto\n","def preprocess_text(text):\n","    # Convertir a minúsculas\n","    text = text.lower()\n","    # Eliminar puntuación\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    # Eliminar números\n","    text = ''.join([char for char in text if not char.isdigit()])\n","    # Tokenizar palabras\n","    words = text.split()\n","    # Eliminar stopwords\n","    stop_words = set(stopwords.words('spanish'))\n","    words = [word for word in words if word not in stop_words]\n","    # Lematización\n","    lemmatizer = WordNetLemmatizer()\n","    words = [lemmatizer.lemmatize(word) for word in words]\n","    return ' '.join(words)\n","\n","# Aplicar preprocesamiento\n","df['message_cleaned'] = df['message'].apply(preprocess_text)\n","\n","# Separar características y etiquetas\n","X = df['message_cleaned']\n","y = df['label']\n","\n","# Transformar en Bag of Words\n","vectorizer = CountVectorizer()\n","X_bow = vectorizer.fit_transform(X)\n","\n","# Dividir en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n","\n","# Convertir a tipo float32 (requerido por XGBoost)\n","X_train = X_train.toarray().astype(np.float32)\n","X_test = X_test.toarray().astype(np.float32)\n","\n","# Modelo XGBoost\n","xgb_model = XGBClassifier(\n","    objective='multi:softmax',\n","    num_class=3,\n","    eval_metric='mlogloss',\n","    random_state=42,\n","    use_label_encoder=False\n",")\n","\n","# Entrenamiento\n","xgb_model.fit(X_train, y_train)\n","\n","# Predicción\n","y_pred = xgb_model.predict(X_test)\n","\n","# Calcular métricas adicionales\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n","recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n","f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n","\n","# Imprimir resultados\n","print(\"\\nResultados de las métricas:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","\n","# Reporte de clasificación detallado\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"Zq2jXWCp10fC","executionInfo":{"status":"ok","timestamp":1735482920975,"user_tz":180,"elapsed":25435,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"1705cdc7-ba0f-498b-bf17-75491436c9eb"},"execution_count":null,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Unzipping corpora/stopwords.zip.\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","/usr/local/lib/python3.10/dist-packages/xgboost/core.py:158: UserWarning: [14:35:08] WARNING: /workspace/src/learner.cc:740: \n","Parameters: { \"use_label_encoder\" } are not used.\n","\n","  warnings.warn(smsg, UserWarning)\n"]},{"output_type":"stream","name":"stdout","text":["\n","Resultados de las métricas:\n","Accuracy: 0.7742\n","Precision: 0.7920\n","Recall: 0.7742\n","F1 Score: 0.7752\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","     Ninguno       0.77      0.82      0.79        44\n","   Depresión       0.89      0.69      0.77        35\n","    Ansiedad       0.63      0.86      0.73        14\n","\n","    accuracy                           0.77        93\n","   macro avg       0.76      0.79      0.76        93\n","weighted avg       0.79      0.77      0.78        93\n","\n"]}]},{"cell_type":"code","source":[],"metadata":{"id":"KJq81Jmlk_m2"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["GBM - NUEVO EN EL TOP"],"metadata":{"id":"GZemIQPAk_-u"}},{"cell_type":"code","source":["import pandas as pd\n","import numpy as np\n","import string\n","from sklearn.feature_extraction.text import CountVectorizer\n","from sklearn.model_selection import train_test_split\n","from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n","from sklearn.ensemble import GradientBoostingClassifier\n","from nltk.corpus import stopwords\n","from nltk.stem import WordNetLemmatizer\n","import nltk\n","\n","nltk.download('stopwords')\n","nltk.download('wordnet')\n","\n","# Preprocesamiento de texto\n","def preprocess_text(text):\n","    # Convertir a minúsculas\n","    text = text.lower()\n","    # Eliminar puntuación\n","    text = text.translate(str.maketrans('', '', string.punctuation))\n","    # Eliminar números\n","    text = ''.join([char for char in text if not char.isdigit()])\n","    # Tokenizar palabras\n","    words = text.split()\n","    # Eliminar stopwords\n","    stop_words = set(stopwords.words('spanish'))\n","    words = [word for word in words if word not in stop_words]\n","    # Lematización\n","    lemmatizer = WordNetLemmatizer()\n","    words = [lemmatizer.lemmatize(word) for word in words]\n","    return ' '.join(words)\n","\n","# Aplicar preprocesamiento\n","df['message_cleaned'] = df['message'].apply(preprocess_text)\n","\n","# Separar características y etiquetas\n","X = df['message_cleaned']\n","y = df['label']\n","\n","# Transformar en Bag of Words\n","vectorizer = CountVectorizer()\n","X_bow = vectorizer.fit_transform(X)\n","\n","# Dividir en entrenamiento y prueba\n","X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n","\n","# Convertir a tipo float64 (GradientBoostingClassifier lo prefiere así)\n","X_train = X_train.toarray().astype(np.float64)\n","X_test = X_test.toarray().astype(np.float64)\n","\n","# Modelo Gradient Boosting\n","gbm_model = GradientBoostingClassifier(\n","    loss='log_loss',\n","   learning_rate=0.1,\n","   n_estimators=100,\n","   max_depth=3,\n","   subsample=1.0,\n","   max_features=None,\n","   random_state=42\n",")\n","\n","# Entrenamiento\n","gbm_model.fit(X_train, y_train)\n","\n","# Predicción\n","y_pred = gbm_model.predict(X_test)\n","\n","# Calcular métricas\n","accuracy = accuracy_score(y_test, y_pred)\n","precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n","recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n","f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n","\n","# Imprimir resultados\n","print(\"\\nResultados de las métricas:\")\n","print(f\"Accuracy: {accuracy:.4f}\")\n","print(f\"Precision: {precision:.4f}\")\n","print(f\"Recall: {recall:.4f}\")\n","print(f\"F1 Score: {f1:.4f}\")\n","\n","# Reporte de clasificación\n","print(\"\\nReporte de Clasificación:\")\n","print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"uUPvKNmglGah","executionInfo":{"status":"ok","timestamp":1749928891592,"user_tz":180,"elapsed":76057,"user":{"displayName":"Kathia Garcia","userId":"03947002799544824998"}},"outputId":"f8bb07b6-e3a5-4b7d-9304-b48f9be1c149"},"execution_count":9,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package wordnet to /root/nltk_data...\n","[nltk_data]   Package wordnet is already up-to-date!\n"]},{"output_type":"stream","name":"stdout","text":["\n","Resultados de las métricas:\n","Accuracy: 0.6598\n","Precision: 0.6769\n","Recall: 0.6598\n","F1 Score: 0.6534\n","\n","Reporte de Clasificación:\n","              precision    recall  f1-score   support\n","\n","     Ninguno       0.61      0.76      0.67        45\n","   Depresión       0.75      0.49      0.59        37\n","    Ansiedad       0.71      0.80      0.75        15\n","\n","    accuracy                           0.66        97\n","   macro avg       0.69      0.68      0.67        97\n","weighted avg       0.68      0.66      0.65        97\n","\n"]}]}]}