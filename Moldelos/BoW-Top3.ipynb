{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 24654,
     "status": "ok",
     "timestamp": 1749927586024,
     "user": {
      "displayName": "Kathia Garcia",
      "userId": "03947002799544824998"
     },
     "user_tz": 180
    },
    "id": "prvFwN4iZlhs",
    "outputId": "27fc73ea-25be-45ec-dc4f-e7b903167312"
   },
   "outputs": [],
   "source": [
    "## Montar google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "executionInfo": {
     "elapsed": 72,
     "status": "ok",
     "timestamp": 1749927611754,
     "user": {
      "displayName": "Kathia Garcia",
      "userId": "03947002799544824998"
     },
     "user_tz": 180
    },
    "id": "dVtXAJyTZrGD"
   },
   "outputs": [],
   "source": [
    "# Cargar el archivo desde Google Drive\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "# Especifica la ruta completa del archivo en tu Google Drive\n",
    "file_path = 'linkXlsx'\n",
    "\n",
    "# Cargar el archivo Excel en un DataFrame\n",
    "df = pd.read_excel(file_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "kHMsQkjbMwHd"
   },
   "source": [
    "**Random Forest**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 15701,
     "status": "ok",
     "timestamp": 1749927662274,
     "user": {
      "displayName": "Kathia Garcia",
      "userId": "03947002799544824998"
     },
     "user_tz": 180
    },
    "id": "4mDiMhk2akcv",
    "outputId": "98a2cf90-71ff-489d-85c2-b997c79dda23"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from lightgbm import LGBMClassifier\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Eliminar números\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    # Tokenizar palabras\n",
    "    words = text.split()\n",
    "    # Eliminar stopwords\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "df['message_cleaned'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = df['message_cleaned']\n",
    "y = df['label']\n",
    "\n",
    "# Transformar en Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "\n",
    "\n",
    "###############################################################################################\n",
    "# Modelo Random Forest\n",
    "###############################################################################################\n",
    "\n",
    "rf_model = RandomForestClassifier(\n",
    "    max_depth=12,\n",
    "    max_features='sqrt',\n",
    "    min_samples_leaf=1,\n",
    "    min_samples_split=5,\n",
    "    n_estimators=500,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "rf_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = rf_model.predict(X_test)\n",
    "\n",
    "# # Evaluación\n",
    "# accuracy = accuracy_score(y_test, y_pred)\n",
    "# print(f'\\nAccuracy: {accuracy * 100:.2f}%')\n",
    "\n",
    "# # Reporte de clasificación\n",
    "# print(\"\\nReporte de clasificación:\")\n",
    "# print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n",
    "\n",
    "\n",
    "# Calcular métricas adicionales\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nResultados de las métricas:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Reporte de clasificación detallado\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "uFPabuD6Mz93"
   },
   "source": [
    "**LGBM**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "collapsed": true,
    "executionInfo": {
     "elapsed": 359,
     "status": "ok",
     "timestamp": 1749927667641,
     "user": {
      "displayName": "Kathia Garcia",
      "userId": "03947002799544824998"
     },
     "user_tz": 180
    },
    "id": "4ChO6498M2Au",
    "outputId": "9aaa17c2-d32f-44b8-df5b-6d2aeaaf08d7"
   },
   "outputs": [],
   "source": [
    "# Convertir la matriz de características a tipo flotante\n",
    "X_train = X_train.astype(np.float32)\n",
    "X_test = X_test.astype(np.float32)\n",
    "\n",
    "# Modelo LightGBM\n",
    "lgbm_model = LGBMClassifier(\n",
    "    objective='multiclass',\n",
    "    num_class=3,\n",
    "    boosting_type='gbdt',\n",
    "    n_estimators=100,\n",
    "    num_leaves=31,\n",
    "    learning_rate=0.05,\n",
    "    feature_fraction=0.7,\n",
    "    verbosity=-1,\n",
    "    random_state=42,\n",
    "    class_weight='balanced'\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "lgbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = lgbm_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas adicionales\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nResultados de las métricas:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Reporte de clasificación detallado\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "v9OKHRqa1wRm"
   },
   "source": [
    "** **texto en negrita**XG BOOST**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 25435,
     "status": "ok",
     "timestamp": 1735482920975,
     "user": {
      "displayName": "Kathia Garcia",
      "userId": "03947002799544824998"
     },
     "user_tz": 180
    },
    "id": "Zq2jXWCp10fC",
    "outputId": "1705cdc7-ba0f-498b-bf17-75491436c9eb"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "from xgboost import XGBClassifier\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Eliminar números\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    # Tokenizar palabras\n",
    "    words = text.split()\n",
    "    # Eliminar stopwords\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "df['message_cleaned'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = df['message_cleaned']\n",
    "y = df['label']\n",
    "\n",
    "# Transformar en Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir a tipo float32 (requerido por XGBoost)\n",
    "X_train = X_train.toarray().astype(np.float32)\n",
    "X_test = X_test.toarray().astype(np.float32)\n",
    "\n",
    "# Modelo XGBoost\n",
    "xgb_model = XGBClassifier(\n",
    "    objective='multi:softmax',\n",
    "    num_class=3,\n",
    "    eval_metric='mlogloss',\n",
    "    random_state=42,\n",
    "    use_label_encoder=False\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "xgb_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = xgb_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas adicionales\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nResultados de las métricas:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Reporte de clasificación detallado\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "GZemIQPAk_-u"
   },
   "source": [
    "GBM - NUEVO EN EL TOP"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "executionInfo": {
     "elapsed": 76057,
     "status": "ok",
     "timestamp": 1749928891592,
     "user": {
      "displayName": "Kathia Garcia",
      "userId": "03947002799544824998"
     },
     "user_tz": 180
    },
    "id": "uUPvKNmglGah",
    "outputId": "f8bb07b6-e3a5-4b7d-9304-b48f9be1c149"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import string\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report, precision_score, recall_score, f1_score\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import WordNetLemmatizer\n",
    "import nltk\n",
    "\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "\n",
    "# Preprocesamiento de texto\n",
    "def preprocess_text(text):\n",
    "    # Convertir a minúsculas\n",
    "    text = text.lower()\n",
    "    # Eliminar puntuación\n",
    "    text = text.translate(str.maketrans('', '', string.punctuation))\n",
    "    # Eliminar números\n",
    "    text = ''.join([char for char in text if not char.isdigit()])\n",
    "    # Tokenizar palabras\n",
    "    words = text.split()\n",
    "    # Eliminar stopwords\n",
    "    stop_words = set(stopwords.words('spanish'))\n",
    "    words = [word for word in words if word not in stop_words]\n",
    "    # Lematización\n",
    "    lemmatizer = WordNetLemmatizer()\n",
    "    words = [lemmatizer.lemmatize(word) for word in words]\n",
    "    return ' '.join(words)\n",
    "\n",
    "# Aplicar preprocesamiento\n",
    "df['message_cleaned'] = df['message'].apply(preprocess_text)\n",
    "\n",
    "# Separar características y etiquetas\n",
    "X = df['message_cleaned']\n",
    "y = df['label']\n",
    "\n",
    "# Transformar en Bag of Words\n",
    "vectorizer = CountVectorizer()\n",
    "X_bow = vectorizer.fit_transform(X)\n",
    "\n",
    "# Dividir en entrenamiento y prueba\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_bow, y, test_size=0.2, random_state=42)\n",
    "\n",
    "# Convertir a tipo float64 (GradientBoostingClassifier lo prefiere así)\n",
    "X_train = X_train.toarray().astype(np.float64)\n",
    "X_test = X_test.toarray().astype(np.float64)\n",
    "\n",
    "# Modelo Gradient Boosting\n",
    "gbm_model = GradientBoostingClassifier(\n",
    "    loss='log_loss',\n",
    "   learning_rate=0.1,\n",
    "   n_estimators=100,\n",
    "   max_depth=3,\n",
    "   subsample=1.0,\n",
    "   max_features=None,\n",
    "   random_state=42\n",
    ")\n",
    "\n",
    "# Entrenamiento\n",
    "gbm_model.fit(X_train, y_train)\n",
    "\n",
    "# Predicción\n",
    "y_pred = gbm_model.predict(X_test)\n",
    "\n",
    "# Calcular métricas\n",
    "accuracy = accuracy_score(y_test, y_pred)\n",
    "precision = precision_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "recall = recall_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "f1 = f1_score(y_test, y_pred, average='weighted', zero_division=0)\n",
    "\n",
    "# Imprimir resultados\n",
    "print(\"\\nResultados de las métricas:\")\n",
    "print(f\"Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Precision: {precision:.4f}\")\n",
    "print(f\"Recall: {recall:.4f}\")\n",
    "print(f\"F1 Score: {f1:.4f}\")\n",
    "\n",
    "# Reporte de clasificación\n",
    "print(\"\\nReporte de Clasificación:\")\n",
    "print(classification_report(y_test, y_pred, target_names=['Ninguno', 'Depresión', 'Ansiedad']))\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "name": "python3"
  },
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
