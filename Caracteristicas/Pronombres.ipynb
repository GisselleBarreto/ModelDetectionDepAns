{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"provenance":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"language_info":{"name":"python"}},"cells":[{"cell_type":"code","source":["from google.colab import drive\n","drive.mount('/content/drive')"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"LyzQqazyBOAB","executionInfo":{"status":"ok","timestamp":1739779180029,"user_tz":180,"elapsed":25114,"user":{"displayName":"Gisselle Barreto","userId":"01486531895219062980"}},"outputId":"70d3cc96-414f-47e1-cf39-22356acea1a5"},"execution_count":1,"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n"]}]},{"cell_type":"code","source":["import pandas as pd\n","import nltk\n","from nltk.tokenize import word_tokenize\n","from nltk.corpus import stopwords\n","import matplotlib.pyplot as plt\n"],"metadata":{"id":"GgVYSPf_An4o","executionInfo":{"status":"ok","timestamp":1739779187960,"user_tz":180,"elapsed":3177,"user":{"displayName":"Gisselle Barreto","userId":"01486531895219062980"}}},"execution_count":2,"outputs":[]},{"cell_type":"code","source":["nltk.download('punkt')\n","nltk.download('stopwords')\n","nltk.download('punkt_tab')\n","\n","# Lista de pronombres en primera persona\n","first_person_pronouns = [\"yo\", \"me\", \"mi\", \"mío\", \"mía\", \"mí\", \"nosotros\", \"nosotras\", \"nos\", \"nuestro\", \"nuestra\", \"nuestros\", \"nuestras\"]\n","\n","# Función para marcar presencia de pronombres de primera persona en un mensaje\n","def marcar_pronombres(message):\n","    tokens = word_tokenize(message.lower())\n","    presence = {pronoun: 1 if pronoun in tokens else 0 for pronoun in first_person_pronouns}\n","    return pd.Series(presence)\n","\n","# Cargar datos\n","#data = pd.read_csv('/content/drive/MyDrive/Tesis- Borradores/FASE 1/TRAIN/data_train.csv')\n","data = pd.read_csv ('/content/drive/MyDrive/Tesis- Borradores/Fase Final ()/Datos de Prueba/Datos/TRAIN Y TRIAL/trainytrial.csv')\n","\n","\n","# Aplicar la función a cada mensaje\n","pronouns_presence = data['message'].apply(marcar_pronombres)\n","\n","# Concatenar las nuevas columnas al DataFrame original\n","data = pd.concat([data, pronouns_presence], axis=1)\n","\n","# Guardar el DataFrame actualizado en un nuevo archivo CSV\n","data.to_csv('/content/drive/MyDrive/Tesis- Borradores/Fase Final ()/Datos de Prueba/Datos/TRAIN Y TRIAL/trainytrial.csv', index=False)\n","\n","# Verificar que las nuevas columnas han sido añadidas correctamente\n","print(data.head())\n","\n"],"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"id":"gor6C6ZXA8hv","executionInfo":{"status":"ok","timestamp":1739779275024,"user_tz":180,"elapsed":11837,"user":{"displayName":"Gisselle Barreto","userId":"01486531895219062980"}},"outputId":"d6febe28-1738-4a70-8043-f9708199c02f"},"execution_count":4,"outputs":[{"output_type":"stream","name":"stderr","text":["[nltk_data] Downloading package punkt to /root/nltk_data...\n","[nltk_data]   Package punkt is already up-to-date!\n","[nltk_data] Downloading package stopwords to /root/nltk_data...\n","[nltk_data]   Package stopwords is already up-to-date!\n","[nltk_data] Downloading package punkt_tab to /root/nltk_data...\n","[nltk_data]   Unzipping tokenizers/punkt_tab.zip.\n"]},{"output_type":"stream","name":"stdout","text":["     id_message                                      message  \\\n","0  1.818584e+10          No cumplire mis sueños de viajar :(   \n","1  1.824850e+10        Y como andan ustedes el dia de hoy :D   \n","2  1.403002e+10    No :( porque el costo de viaje es caro :(   \n","3  1.475234e+09        para ir a japon pero voy a ahorrar :D   \n","4  8.810838e+10  Si su cultura es muy diversa y Divertida :D   \n","\n","                  date subject_id  label  toxicity sentiment       POS  \\\n","0  2022-03-23 17:17:09  subject16      0       0.0       NEG  0.005048   \n","1  2022-03-23 17:17:51  subject16      0       0.0       NEU  0.477511   \n","2  2022-03-23 17:18:49  subject16      0       0.0       NEG  0.003649   \n","3  2022-03-23 17:20:42  subject16      0       0.0       NEU  0.086344   \n","4  2022-03-23 17:27:18  subject16      0       0.0       POS  0.978419   \n","\n","        NEG       NEU  ...  mío  mía  mí  nosotros  nosotras  nos  nuestro  \\\n","0  0.926497  0.068455  ...    0    0   0         0         0    0        0   \n","1  0.021999  0.500490  ...    0    0   0         0         0    0        0   \n","2  0.941742  0.054609  ...    0    0   0         0         0    0        0   \n","3  0.046226  0.867430  ...    0    0   0         0         0    0        0   \n","4  0.001868  0.019713  ...    0    0   0         0         0    0        0   \n","\n","   nuestra  nuestros  nuestras  \n","0        0         0         0  \n","1        0         0         0  \n","2        0         0         0  \n","3        0         0         0  \n","4        0         0         0  \n","\n","[5 rows x 29 columns]\n"]}]},{"cell_type":"code","source":["#intento en FreeLing\n","\n","import pandas as pd\n","import subprocess\n","import os\n","\n","# Lista de pronombres en primera persona\n","first_person_pronouns = [\"yo\", \"me\", \"mi\", \"mío\", \"mía\", \"mí\", \"nosotros\", \"nosotras\", \"nos\", \"nuestro\", \"nuestra\", \"nuestros\", \"nuestras\"]\n","\n","# Función para usar FreeLing y contar pronombres de primera persona en un mensaje\n","def contar_pronombres_freeling(mensaje):\n","    # Guardar el mensaje en un archivo temporal\n","    with open(\"temp.txt\", \"w\", encoding=\"utf-8\") as file:\n","        file.write(mensaje)\n","\n","    # Ejecutar FreeLing en el archivo temporal\n","    result = subprocess.run(['analyze', '-f', 'es.cfg'], input=mensaje, text=True, capture_output=True)\n","\n","    # Leer el resultado\n","    output = result.stdout\n","\n","    # Procesar el resultado para contar los pronombres\n","    tokens = [line.split()[0] for line in output.split('\\n') if line and not line.startswith('#')]\n","    pronombres_encontrados = [palabra for palabra in tokens if palabra.lower() in first_person_pronouns]\n","    return len(pronombres_encontrados), ', '.join(pronombres_encontrados)\n","\n","# Cargar datos\n","data = pd.read_csv('/content/drive/MyDrive/Tesis- Borradores/FASE 1/TRIAL/combined_data_trial.csv')\n","\n","# Aplicar la función a cada mensaje\n","data[['Total_pronombres', 'Pronombres_encontrados']] = data['message'].apply(lambda x: pd.Series(contar_pronombres_freeling(x)))\n","\n","# Guardar el DataFrame actualizado en un nuevo archivo CSV\n","data.to_csv('/content/drive/MyDrive/Tesis- Borradores/FASE 1/TRIAL/combined_data_trial3.csv', index=False)\n","\n","# Verificar que las nuevas columnas han sido añadidas correctamente\n","print(data.head())\n"],"metadata":{"id":"xJZFw_XrqNbA"},"execution_count":null,"outputs":[]}]}